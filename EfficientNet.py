# -*- coding: utf-8 -*-
"""EfficientNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QRI84cYRBThI0hr04EdUE5OE-wEqGjBU?usp=drive_link
"""

# Import các thư viện
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, BatchNormalization, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns
import pandas as pd

# 1. Tải dữ liệu Fashion MNIST từ Keras
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

# Thông tin về dữ liệu
print("Kích thước x_train:", x_train.shape)  # (60000, 28, 28)
print("Kích thước y_train:", y_train.shape)  # (60000,)
print("Kích thước x_test:", x_test.shape)    # (10000, 28, 28)
print("Kích thước y_test:", y_test.shape)    # (10000,)

# Kiểm tra số lượng mẫu trên từng lớp
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

import collections
train_label_counts = collections.Counter(y_train)
print("\nSố lượng ảnh mỗi lớp trong tập huấn luyện:")
for i, class_name in enumerate(class_names):
    print(f"{class_name:12}: {train_label_counts[i]} ảnh")

#  Hiển thị một vài ảnh minh họa
plt.figure(figsize=(10, 3))
for i in range(10):
    plt.subplot(1, 10, i+1)
    plt.imshow(x_train[i], cmap="gray")
    plt.title(y_train[i])
    plt.axis("off")
plt.suptitle("Một số ảnh ví dụ từ Fashion MNIST", fontsize=14)
plt.show()

# Kích thước ảnh mới (EfficientNetB0 yêu cầu kích thước đầu vào >=32x32)
IMG_SIZE = 48

# 2. Tiền xử lý ảnh: mở rộng thành ảnh RGB và resize về kích thước 48x48
x_train = np.expand_dims(x_train, -1)  # Thêm kênh màu
x_test = np.expand_dims(x_test, -1)
x_train = np.repeat(x_train, 3, axis=-1)  # Lặp lại để thành ảnh RGB (3 kênh)
x_test = np.repeat(x_test, 3, axis=-1)

# Resize và chuẩn hóa ảnh về khoảng [0, 1]
x_train = tf.image.resize(x_train, (IMG_SIZE, IMG_SIZE)).numpy() / 255.0
x_test = tf.image.resize(x_test, (IMG_SIZE, IMG_SIZE)).numpy() / 255.0

# Danh sách tên các lớp
num_classes = 10
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# 3. Data Augmentation để tăng đa dạng dữ liệu huấn luyện
data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.1),
])

# Hàm dùng để áp dụng data augmentation
def augment(images, labels):
    return data_augmentation(images), labels

# Tạo dataset dùng tf.data để tối ưu hiệu năng
batch_size = 32
AUTOTUNE = tf.data.AUTOTUNE

train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_ds = train_ds.shuffle(10000).batch(batch_size).map(augment).prefetch(AUTOTUNE)

val_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size).prefetch(AUTOTUNE)

# 4. Xây dựng mô hình sử dụng EfficientNetB0 làm backbone
base_model = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)  # Không dùng weight pre-trained
base_model.trainable = True  # Cho phép fine-tuning toàn bộ mô hình

# Xây dựng kiến trúc
inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = base_model(inputs)
x = GlobalAveragePooling2D()(x)  # Tính trung bình không gian
x = BatchNormalization()(x)  # Chuẩn hóa giúp tăng ổn định mô hình
x = Dropout(0.4)(x)  # Regularization để tránh overfitting
outputs = Dense(num_classes, activation='softmax')(x)  # Lớp đầu ra với softmax

model = Model(inputs, outputs)

# Compile mô hình
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

# 5. Huấn luyện mô hình với EarlyStopping và ReduceLROnPlateau
early_stop = EarlyStopping(patience=3, restore_best_weights=True)  # Dừng sớm nếu val_loss không cải thiện
reduce_lr = ReduceLROnPlateau(factor=0.5, patience=2)  # Giảm learning rate nếu val_loss không giảm

history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=20,
                    callbacks=[early_stop, reduce_lr])

# 6. Đánh giá mô hình trên tập kiểm tra
loss, acc = model.evaluate(val_ds)
print(f"\nTest accuracy: {acc:.4f}")

# 7. Vẽ biểu đồ Accuracy và Loss qua từng epoch
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# 8. Dự đoán trên tập kiểm tra
preds = model.predict(x_test)
pred_labels = np.argmax(preds, axis=1)

# Confusion matrix
cm = confusion_matrix(y_test, pred_labels)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Classification report
report = classification_report(y_test, pred_labels, target_names=class_names)
print("Classification Report:\n", report)

# Bảng tóm tắt các chỉ số đánh giá
metrics_summary = {
    "Accuracy": accuracy_score(y_test, pred_labels),
    "Precision (Macro)": precision_score(y_test, pred_labels, average='macro'),
    "Recall (Macro)": recall_score(y_test, pred_labels, average='macro'),
    "F1-Score (Macro)": f1_score(y_test, pred_labels, average='macro'),
}
metrics_df = pd.DataFrame(metrics_summary, index=["Score"])
print("\nTóm tắt chỉ số đánh giá:")
print(metrics_df)

# Hiển thị 5 ảnh được dự đoán đúng và 5 ảnh sai
correct_indices = np.where(pred_labels == y_test)[0]
wrong_indices = np.where(pred_labels != y_test)[0]

# 5 ảnh dự đoán đúng
plt.figure(figsize=(10, 4))
for i, idx in enumerate(correct_indices[:5]):
    plt.subplot(1, 5, i+1)
    plt.imshow(x_test[idx])
    plt.title(f"✓ {class_names[pred_labels[idx]]}", color='green')
    plt.axis('off')
plt.suptitle("5 Dự đoán ĐÚNG", fontsize=14)
plt.tight_layout()
plt.show()

# 5 ảnh dự đoán sai
plt.figure(figsize=(10, 4))
for i, idx in enumerate(wrong_indices[:5]):
    plt.subplot(1, 5, i+1)
    plt.imshow(x_test[idx])
    true_label = class_names[y_test[idx]]
    pred_label = class_names[pred_labels[idx]]
    plt.title(f"T:{true_label}\nP:{pred_label}", color='red')
    plt.axis('off')
plt.suptitle("5 Dự đoán SAI", fontsize=14)
plt.tight_layout()
plt.show()